{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac54ba3e-0fba-48f3-b8f9-ffa95e3825c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 1563] Loss: 28.908\n",
      "Accuracy after epoch 1: 39.02%\n",
      "[Epoch 2, Batch 1563] Loss: 25.046\n",
      "Accuracy after epoch 2: 43.59%\n",
      "[Epoch 3, Batch 1563] Loss: 22.805\n",
      "Accuracy after epoch 3: 49.94%\n",
      "[Epoch 4, Batch 1563] Loss: 21.027\n",
      "Accuracy after epoch 4: 52.80%\n",
      "[Epoch 5, Batch 1563] Loss: 19.722\n",
      "Accuracy after epoch 5: 55.54%\n",
      "[Epoch 6, Batch 1563] Loss: 18.475\n",
      "Accuracy after epoch 6: 56.82%\n",
      "[Epoch 7, Batch 1563] Loss: 17.581\n",
      "Accuracy after epoch 7: 58.93%\n",
      "[Epoch 8, Batch 1563] Loss: 16.669\n",
      "Accuracy after epoch 8: 60.26%\n",
      "[Epoch 9, Batch 1563] Loss: 15.990\n",
      "Accuracy after epoch 9: 61.54%\n",
      "[Epoch 10, Batch 1563] Loss: 15.292\n",
      "Accuracy after epoch 10: 62.38%\n",
      "[Epoch 11, Batch 1563] Loss: 14.912\n",
      "Accuracy after epoch 11: 63.11%\n",
      "[Epoch 12, Batch 1563] Loss: 14.468\n",
      "Accuracy after epoch 12: 63.41%\n",
      "[Epoch 13, Batch 1563] Loss: 13.743\n",
      "Accuracy after epoch 13: 64.69%\n",
      "[Epoch 14, Batch 1563] Loss: 13.464\n",
      "Accuracy after epoch 14: 65.07%\n",
      "[Epoch 15, Batch 1563] Loss: 19.324\n",
      "Accuracy after epoch 15: 63.73%\n",
      "[Epoch 16, Batch 1563] Loss: 13.677\n",
      "Accuracy after epoch 16: 65.41%\n",
      "[Epoch 17, Batch 1563] Loss: 12.798\n",
      "Accuracy after epoch 17: 66.62%\n",
      "[Epoch 18, Batch 1563] Loss: 12.329\n",
      "Accuracy after epoch 18: 66.63%\n",
      "[Epoch 19, Batch 1563] Loss: 12.060\n",
      "Accuracy after epoch 19: 66.47%\n",
      "[Epoch 20, Batch 1563] Loss: 11.940\n",
      "Accuracy after epoch 20: 65.60%\n",
      "[Epoch 21, Batch 1563] Loss: 12.071\n",
      "Accuracy after epoch 21: 66.12%\n",
      "[Epoch 22, Batch 1563] Loss: 11.821\n",
      "Accuracy after epoch 22: 66.01%\n",
      "[Epoch 23, Batch 1563] Loss: 11.491\n",
      "Accuracy after epoch 23: 67.46%\n",
      "[Epoch 24, Batch 1563] Loss: 11.207\n",
      "Accuracy after epoch 24: 67.06%\n",
      "[Epoch 25, Batch 1563] Loss: 11.063\n",
      "Accuracy after epoch 25: 66.08%\n",
      "[Epoch 26, Batch 1563] Loss: 11.266\n",
      "Accuracy after epoch 26: 66.47%\n",
      "[Epoch 27, Batch 1563] Loss: 17.751\n",
      "Accuracy after epoch 27: 63.01%\n",
      "[Epoch 28, Batch 1563] Loss: 11.643\n",
      "Accuracy after epoch 28: 67.09%\n",
      "[Epoch 29, Batch 1563] Loss: 10.291\n",
      "Accuracy after epoch 29: 67.60%\n",
      "[Epoch 30, Batch 1563] Loss: 9.853\n",
      "Accuracy after epoch 30: 67.56%\n",
      "[Epoch 31, Batch 1563] Loss: 9.658\n",
      "Accuracy after epoch 31: 67.07%\n",
      "[Epoch 32, Batch 1563] Loss: 9.626\n",
      "Accuracy after epoch 32: 66.90%\n",
      "[Epoch 33, Batch 1563] Loss: 9.553\n",
      "Accuracy after epoch 33: 67.08%\n",
      "[Epoch 34, Batch 1563] Loss: 9.683\n",
      "Accuracy after epoch 34: 67.05%\n",
      "[Epoch 35, Batch 1563] Loss: 14.409\n",
      "Accuracy after epoch 35: 66.27%\n",
      "[Epoch 36, Batch 1563] Loss: 9.965\n",
      "Accuracy after epoch 36: 67.63%\n",
      "[Epoch 37, Batch 1563] Loss: 9.086\n",
      "Accuracy after epoch 37: 67.57%\n",
      "[Epoch 38, Batch 1563] Loss: 8.792\n",
      "Accuracy after epoch 38: 67.39%\n",
      "[Epoch 39, Batch 1563] Loss: 8.721\n",
      "Accuracy after epoch 39: 66.72%\n",
      "[Epoch 40, Batch 1563] Loss: 27.111\n",
      "Accuracy after epoch 40: 57.04%\n",
      "[Epoch 41, Batch 1563] Loss: 15.419\n",
      "Accuracy after epoch 41: 62.33%\n",
      "[Epoch 42, Batch 1563] Loss: 12.779\n",
      "Accuracy after epoch 42: 65.59%\n",
      "[Epoch 43, Batch 1563] Loss: 10.994\n",
      "Accuracy after epoch 43: 66.63%\n",
      "[Epoch 44, Batch 1563] Loss: 25.690\n",
      "Accuracy after epoch 44: 64.36%\n",
      "[Epoch 45, Batch 1563] Loss: 11.257\n",
      "Accuracy after epoch 45: 67.05%\n",
      "[Epoch 46, Batch 1563] Loss: 10.092\n",
      "Accuracy after epoch 46: 67.47%\n",
      "[Epoch 47, Batch 1563] Loss: 9.448\n",
      "Accuracy after epoch 47: 67.67%\n",
      "[Epoch 48, Batch 1563] Loss: 9.067\n",
      "Accuracy after epoch 48: 67.58%\n",
      "[Epoch 49, Batch 1563] Loss: 8.852\n",
      "Accuracy after epoch 49: 67.89%\n",
      "[Epoch 50, Batch 1563] Loss: 12.114\n",
      "Accuracy after epoch 50: 66.79%\n",
      "[Epoch 51, Batch 1563] Loss: 9.799\n",
      "Accuracy after epoch 51: 67.90%\n",
      "[Epoch 52, Batch 1563] Loss: 8.735\n",
      "Accuracy after epoch 52: 68.23%\n",
      "[Epoch 53, Batch 1563] Loss: 8.433\n",
      "Accuracy after epoch 53: 67.97%\n",
      "[Epoch 54, Batch 1563] Loss: 8.627\n",
      "Accuracy after epoch 54: 68.06%\n",
      "[Epoch 55, Batch 1563] Loss: 8.241\n",
      "Accuracy after epoch 55: 67.07%\n",
      "[Epoch 56, Batch 1563] Loss: 8.764\n",
      "Accuracy after epoch 56: 67.78%\n",
      "[Epoch 57, Batch 1563] Loss: 8.329\n",
      "Accuracy after epoch 57: 67.29%\n",
      "[Epoch 58, Batch 1563] Loss: 7.780\n",
      "Accuracy after epoch 58: 68.00%\n",
      "[Epoch 59, Batch 1563] Loss: 7.692\n",
      "Accuracy after epoch 59: 67.89%\n",
      "[Epoch 60, Batch 1563] Loss: 7.614\n",
      "Accuracy after epoch 60: 68.15%\n",
      "[Epoch 61, Batch 1563] Loss: 7.761\n",
      "Accuracy after epoch 61: 67.35%\n",
      "[Epoch 62, Batch 1563] Loss: 7.458\n",
      "Accuracy after epoch 62: 66.58%\n",
      "[Epoch 63, Batch 1563] Loss: 9.309\n",
      "Accuracy after epoch 63: 67.06%\n",
      "[Epoch 64, Batch 1563] Loss: 7.289\n",
      "Accuracy after epoch 64: 68.02%\n",
      "[Epoch 65, Batch 1563] Loss: 6.721\n",
      "Accuracy after epoch 65: 68.14%\n",
      "[Epoch 66, Batch 1563] Loss: 6.863\n",
      "Accuracy after epoch 66: 67.35%\n",
      "[Epoch 67, Batch 1563] Loss: 6.968\n",
      "Accuracy after epoch 67: 68.20%\n",
      "[Epoch 68, Batch 1563] Loss: 6.770\n",
      "Accuracy after epoch 68: 67.63%\n",
      "[Epoch 69, Batch 1563] Loss: 6.725\n",
      "Accuracy after epoch 69: 67.31%\n",
      "[Epoch 70, Batch 1563] Loss: 6.512\n",
      "Accuracy after epoch 70: 67.07%\n",
      "[Epoch 71, Batch 1563] Loss: 6.674\n",
      "Accuracy after epoch 71: 65.83%\n",
      "[Epoch 72, Batch 1563] Loss: 6.546\n",
      "Accuracy after epoch 72: 67.34%\n",
      "[Epoch 73, Batch 1563] Loss: 6.359\n",
      "Accuracy after epoch 73: 67.67%\n",
      "[Epoch 74, Batch 1563] Loss: 6.119\n",
      "Accuracy after epoch 74: 66.54%\n",
      "[Epoch 75, Batch 1563] Loss: 6.266\n",
      "Accuracy after epoch 75: 66.62%\n",
      "[Epoch 76, Batch 1563] Loss: 6.072\n",
      "Accuracy after epoch 76: 67.18%\n",
      "[Epoch 77, Batch 1563] Loss: 6.160\n",
      "Accuracy after epoch 77: 66.71%\n",
      "[Epoch 78, Batch 1563] Loss: 6.139\n",
      "Accuracy after epoch 78: 67.58%\n",
      "[Epoch 79, Batch 1563] Loss: 5.955\n",
      "Accuracy after epoch 79: 67.70%\n",
      "[Epoch 80, Batch 1563] Loss: 5.711\n",
      "Accuracy after epoch 80: 66.73%\n",
      "[Epoch 81, Batch 1563] Loss: 9.231\n",
      "Accuracy after epoch 81: 67.21%\n",
      "[Epoch 82, Batch 1563] Loss: 6.083\n",
      "Accuracy after epoch 82: 67.42%\n",
      "[Epoch 83, Batch 1563] Loss: 5.310\n",
      "Accuracy after epoch 83: 67.74%\n",
      "[Epoch 84, Batch 1563] Loss: 5.293\n",
      "Accuracy after epoch 84: 67.32%\n",
      "[Epoch 85, Batch 1563] Loss: 5.314\n",
      "Accuracy after epoch 85: 66.27%\n",
      "[Epoch 86, Batch 1563] Loss: 5.277\n",
      "Accuracy after epoch 86: 67.14%\n",
      "[Epoch 87, Batch 1563] Loss: 5.608\n",
      "Accuracy after epoch 87: 66.03%\n",
      "[Epoch 88, Batch 1563] Loss: 7.297\n",
      "Accuracy after epoch 88: 66.21%\n",
      "[Epoch 89, Batch 1563] Loss: 5.150\n",
      "Accuracy after epoch 89: 66.74%\n",
      "[Epoch 90, Batch 1563] Loss: 4.827\n",
      "Accuracy after epoch 90: 66.68%\n",
      "[Epoch 91, Batch 1563] Loss: 4.983\n",
      "Accuracy after epoch 91: 66.16%\n",
      "[Epoch 92, Batch 1563] Loss: 5.211\n",
      "Accuracy after epoch 92: 65.43%\n",
      "[Epoch 93, Batch 1563] Loss: 6.391\n",
      "Accuracy after epoch 93: 62.89%\n",
      "[Epoch 94, Batch 1563] Loss: 5.502\n",
      "Accuracy after epoch 94: 67.14%\n",
      "[Epoch 95, Batch 1563] Loss: 5.033\n",
      "Accuracy after epoch 95: 66.32%\n",
      "[Epoch 96, Batch 1563] Loss: 4.854\n",
      "Accuracy after epoch 96: 67.28%\n",
      "[Epoch 97, Batch 1563] Loss: 5.545\n",
      "Accuracy after epoch 97: 64.82%\n",
      "[Epoch 98, Batch 1563] Loss: 6.023\n",
      "Accuracy after epoch 98: 66.86%\n",
      "[Epoch 99, Batch 1563] Loss: 4.689\n",
      "Accuracy after epoch 99: 66.33%\n",
      "[Epoch 100, Batch 1563] Loss: 4.784\n",
      "Accuracy after epoch 100: 66.46%\n",
      "[Epoch 101, Batch 1563] Loss: 4.926\n",
      "Accuracy after epoch 101: 67.11%\n",
      "[Epoch 102, Batch 1563] Loss: 4.869\n",
      "Accuracy after epoch 102: 67.22%\n",
      "[Epoch 103, Batch 1563] Loss: 4.790\n",
      "Accuracy after epoch 103: 66.84%\n",
      "[Epoch 104, Batch 1563] Loss: 4.793\n",
      "Accuracy after epoch 104: 65.73%\n",
      "[Epoch 105, Batch 1563] Loss: 4.683\n",
      "Accuracy after epoch 105: 66.46%\n",
      "[Epoch 106, Batch 1563] Loss: 4.800\n",
      "Accuracy after epoch 106: 65.11%\n",
      "[Epoch 107, Batch 1563] Loss: 6.634\n",
      "Accuracy after epoch 107: 66.31%\n",
      "[Epoch 108, Batch 1563] Loss: 2943.730\n",
      "Accuracy after epoch 108: 46.99%\n",
      "[Epoch 109, Batch 1563] Loss: 20.991\n",
      "Accuracy after epoch 109: 52.74%\n",
      "[Epoch 110, Batch 1563] Loss: 17.987\n",
      "Accuracy after epoch 110: 55.61%\n",
      "[Epoch 111, Batch 1563] Loss: 16.398\n",
      "Accuracy after epoch 111: 57.88%\n",
      "[Epoch 112, Batch 1563] Loss: 15.160\n",
      "Accuracy after epoch 112: 59.86%\n",
      "[Epoch 113, Batch 1563] Loss: 14.030\n",
      "Accuracy after epoch 113: 61.61%\n",
      "[Epoch 114, Batch 1563] Loss: 12.920\n",
      "Accuracy after epoch 114: 62.79%\n",
      "[Epoch 115, Batch 1563] Loss: 11.781\n",
      "Accuracy after epoch 115: 64.54%\n",
      "[Epoch 116, Batch 1563] Loss: 10.584\n",
      "Accuracy after epoch 116: 66.38%\n",
      "[Epoch 117, Batch 1563] Loss: 9.253\n",
      "Accuracy after epoch 117: 66.52%\n",
      "[Epoch 118, Batch 1563] Loss: 7.994\n",
      "Accuracy after epoch 118: 67.85%\n",
      "[Epoch 119, Batch 1563] Loss: 6.769\n",
      "Accuracy after epoch 119: 67.82%\n",
      "[Epoch 120, Batch 1563] Loss: 5.905\n",
      "Accuracy after epoch 120: 67.45%\n",
      "[Epoch 121, Batch 1563] Loss: 5.289\n",
      "Accuracy after epoch 121: 66.84%\n",
      "[Epoch 122, Batch 1563] Loss: 4.881\n",
      "Accuracy after epoch 122: 67.31%\n",
      "[Epoch 123, Batch 1563] Loss: 5.023\n",
      "Accuracy after epoch 123: 67.46%\n",
      "[Epoch 124, Batch 1563] Loss: 4.737\n",
      "Accuracy after epoch 124: 66.39%\n",
      "[Epoch 125, Batch 1563] Loss: 7.183\n",
      "Accuracy after epoch 125: 45.16%\n",
      "[Epoch 126, Batch 1563] Loss: 11.941\n",
      "Accuracy after epoch 126: 68.07%\n",
      "[Epoch 127, Batch 1563] Loss: 5.896\n",
      "Accuracy after epoch 127: 67.66%\n",
      "[Epoch 128, Batch 1563] Loss: 4.621\n",
      "Accuracy after epoch 128: 67.08%\n",
      "[Epoch 129, Batch 1563] Loss: 4.453\n",
      "Accuracy after epoch 129: 67.10%\n",
      "[Epoch 130, Batch 1563] Loss: 4.647\n",
      "Accuracy after epoch 130: 66.02%\n",
      "[Epoch 131, Batch 1563] Loss: 1574.171\n",
      "Accuracy after epoch 131: 34.51%\n",
      "[Epoch 132, Batch 1563] Loss: 32.518\n",
      "Accuracy after epoch 132: 42.96%\n",
      "[Epoch 133, Batch 1563] Loss: 24.557\n",
      "Accuracy after epoch 133: 47.01%\n",
      "[Epoch 134, Batch 1563] Loss: 21.695\n",
      "Accuracy after epoch 134: 50.99%\n",
      "[Epoch 135, Batch 1563] Loss: 19.685\n",
      "Accuracy after epoch 135: 53.38%\n",
      "[Epoch 136, Batch 1563] Loss: 17.937\n",
      "Accuracy after epoch 136: 56.50%\n",
      "[Epoch 137, Batch 1563] Loss: 15.954\n",
      "Accuracy after epoch 137: 60.36%\n",
      "[Epoch 138, Batch 1563] Loss: 13.442\n",
      "Accuracy after epoch 138: 63.40%\n",
      "[Epoch 139, Batch 1563] Loss: 10.539\n",
      "Accuracy after epoch 139: 66.27%\n",
      "[Epoch 140, Batch 1563] Loss: 8.199\n",
      "Accuracy after epoch 140: 66.85%\n",
      "[Epoch 141, Batch 1563] Loss: 6.486\n",
      "Accuracy after epoch 141: 67.18%\n",
      "[Epoch 142, Batch 1563] Loss: 5.424\n",
      "Accuracy after epoch 142: 67.37%\n",
      "[Epoch 143, Batch 1563] Loss: 4.828\n",
      "Accuracy after epoch 143: 67.20%\n",
      "[Epoch 144, Batch 1563] Loss: 4.640\n",
      "Accuracy after epoch 144: 66.13%\n",
      "[Epoch 145, Batch 1563] Loss: 5.197\n",
      "Accuracy after epoch 145: 66.90%\n",
      "[Epoch 146, Batch 1563] Loss: 4.570\n",
      "Accuracy after epoch 146: 66.54%\n",
      "[Epoch 147, Batch 1563] Loss: 4.584\n",
      "Accuracy after epoch 147: 67.06%\n",
      "[Epoch 148, Batch 1563] Loss: 4.397\n",
      "Accuracy after epoch 148: 66.22%\n",
      "[Epoch 149, Batch 1563] Loss: 4.452\n",
      "Accuracy after epoch 149: 66.66%\n",
      "[Epoch 150, Batch 1563] Loss: 4.931\n",
      "Accuracy after epoch 150: 66.45%\n",
      "Finished Training\n",
      "Model saved as 'mamba_cifar.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "patch_size = 4\n",
    "hidden_size = 64\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "epochs = 150\n",
    "learning_rate = 0.001\n",
    "img_size = 32\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Dataset and Dataloader\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Mamba Block for 2D input\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.mamba = Mamba(d_model=d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.view(B, C, -1).transpose(1, 2)  # [B, HW, C]\n",
    "        x = self.mamba(x)\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Vision Mamba Classifier using Mamba Blocks\n",
    "class VisionMambaClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(3, hidden_size, kernel_size=patch_size, stride=patch_size)\n",
    "        self.block1 = MambaBlock(d_model=hidden_size)\n",
    "        self.block2 = MambaBlock(d_model=hidden_size)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)           # [B, hidden, H', W']\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize and train the model\n",
    "model = VisionMambaClassifier(hidden_size, num_classes, patch_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'[Epoch {epoch+1}, Batch {i+1}] Loss: {running_loss / 100:.3f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy after epoch {epoch+1}: {100 * correct / total:.2f}%')\n",
    "\n",
    "print('Finished Training')\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), \"mamba_cifar.pth\")\n",
    "print(\"Model saved as 'mamba_cifar.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788cbc88-46bd-4eab-8985-f533c00b1f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionMambaClassifier(\n",
       "  (patch_embed): Conv2d(3, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "  (block1): MambaBlock(\n",
       "    (mamba): Mamba(\n",
       "      (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
       "      (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "      (act): SiLU()\n",
       "      (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
       "      (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (block2): MambaBlock(\n",
       "    (mamba): Mamba(\n",
       "      (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
       "      (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "      (act): SiLU()\n",
       "      (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
       "      (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and reuse the model\n",
    "model = VisionMambaClassifier(hidden_size, num_classes, patch_size).to(device)\n",
    "model.load_state_dict(torch.load(\"mamba_cifar.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdc07ca-8cbf-4feb-8727-f06c713c82ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.84313726..0.96862745].\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAADECAYAAACCwKrVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJmBJREFUeJzt3Xt0VNX5N/BvhmQySSYhhCSEiLkQiJSbtEHlIgQpIIRLLS/mBaQFCpWFCLIUbcEqBGhpC7VQbkLLrULR4oW+IlahXAuKCoSrYAIJFyOEEIYYQhgms98/+GV+nHl2YEAubv1+1nItz8Oec/bMOfPMyXnO3idIKaVARETGst3tDhAR0TfDRE5EZDgmciIiwzGRExEZjomciMhwTORERIZjIiciMhwTORGR4ZjIiYgMZ1wiT0lJwZAhQ3zLmzZtQlBQEDZt2nTX+uTPv48UuE6dOqF58+bXbVdYWIigoCAsXbrUF5s0aRKCgoJuY+/MN2TIEKSkpNztbhip+vgqKSm5bts7naduKJEvXboUQUFBvv8cDgfS09Px9NNP4/Tp07elg7fL2rVrMWnSpLvdjTviH//4B2bOnHm3u/Gd43K54HA4EBQUhM8///ym1zNv3jzLD9L3yfbt2zFp0iS4XK673RWj3dQZ+eTJk/Haa69hzpw5aNeuHebPn4+2bduioqLiVvfvujp27IiLFy+iY8eON/S6tWvXIicn5zb16tvlu5jIk5OTcfHiRfzsZz+7a31YtWoVgoKCkJCQgBUrVtz0er7viTwnJ+c7l8gPHz6Mv/71r3dsezeVyHv06IFBgwZh+PDhWLp0KcaOHYuCggL861//qvE1Fy5cuOlOXovNZoPD4YDNZtxVIvoGqv8irFWr1l3rw/Lly5GVlYUBAwbgH//4x13rB337hIaGIiQk5I5t75Zkv86dOwMACgoKAFy5Dud0OnHkyBFkZWUhMjISTzzxBADA6/Vi5syZaNasGRwOB+rVq4cRI0bg3LlzlnUqpTB16lQ0aNAA4eHheOSRR3DgwAGx7ZquPe3YsQNZWVmoU6cOIiIi0LJlS8yaNcvXv7lz5wKA5VJRtVvdRwA4cuQIjhw5ct3PsrS0FOPGjUOLFi3gdDoRFRWFHj16YM+ePZZ21Ze5CgsLr/l5dOrUCe+99x6OHTvme59XXyMtLi7GsGHDUK9ePTgcDtx///1YtmyZZZ3V16NnzJiBuXPnomHDhggPD0e3bt1w4sQJKKUwZcoUNGjQAGFhYfjJT36C0tJS8d7mzZuHZs2aITQ0FImJiRg1alSNZ2I7d+5Eu3btEBYWhtTUVLz66qvaPgVyJrt8+XJkZGQgLCwMMTEx6N+/P06cOHHd113L8ePHsXXrVvTv3x/9+/dHQUEBtm/fXuP2H3zwQYSHh6NOnTro2LEjPvzwQwBXrqUeOHAAmzdv9u2fTp06Aaj5mr9u3//rX/9Cz549kZiYiNDQUKSlpWHKlCmoqqq67nv56quvcOjQIVy+fPm6bWfMmIF27dqhbt26CAsLQ0ZGBt58801Lm2vtm6CgIN8lzUmTJuH5558HAKSmpvref/X78ng8mDJlCtLS0hAaGoqUlBRMmDABly5dsqwzJSUFvXr1wqZNm9C6dWuEhYWhRYsWvu/A22+/jRYtWsDhcCAjIwO7d+8W/dqwYQM6dOiAiIgIREdH4yc/+UmNl8tKSkqQnZ2NqKgo1K1bF8888wwqKytFnwKpk+3YsQPdu3dH7dq1ER4ejszMTGzbtu26r/MXfMOv0KhOUHXr1vXFPB4PHn30UTz88MOYMWMGwsPDAQAjRozA0qVLMXToUIwZMwYFBQWYM2cOdu/ejW3btvl+xV5++WVMnToVWVlZyMrKwq5du9CtWze43e7r9mfdunXo1asX6tevj2eeeQYJCQn4/PPPsWbNGjzzzDMYMWIEioqKsG7dOrz22mvi9bejjz/+8Y8BQCRef0ePHsXq1avx+OOPIzU1FadPn8aCBQuQmZmJgwcPIjEx8brv/2ovvvgizp8/j5MnT+LPf/4zAMDpdAIALl68iE6dOiE/Px9PP/00UlNTsWrVKgwZMgQulwvPPPOMZV0rVqyA2+3G6NGjUVpaij/+8Y/Izs5G586dsWnTJvzqV79Cfn4+Zs+ejXHjxmHx4sW+106aNAk5OTno0qULRo4cicOHD2P+/Pn49NNPLZ8pAJw7dw5ZWVnIzs7GgAED8M9//hMjR46E3W7HL37xixt6/7/97W/x0ksvITs7G8OHD8eZM2cwe/ZsdOzYEbt370Z0dPQNra/aypUrERERgV69eiEsLAxpaWlYsWIF2rVrZ2mXk5ODSZMmoV27dpg8eTLsdjt27NiBDRs2oFu3bpg5cyZGjx4Np9OJF198EQBQr169G+7P0qVL4XQ68eyzz8LpdGLDhg14+eWXUVZWhunTp1/ztePHj8eyZctQUFBw3ULorFmz0KdPHzzxxBNwu914/fXX8fjjj2PNmjXo2bPnDfW5b9+++OKLL7By5Ur8+c9/RmxsLAAgLi4OADB8+HAsW7YM/fr1w3PPPYcdO3Zg2rRp+Pzzz/HOO+9Y1pWfn4+BAwdixIgRGDRoEGbMmIHevXvj1VdfxYQJE/DUU08BAKZNm4bs7GwcPnzY91f8+vXr0aNHDzRs2BCTJk3CxYsXMXv2bLRv3x67du0Sn0l2djZSUlIwbdo0fPzxx/jLX/6Cc+fO4e9///sNvf8NGzagR48eyMjIwMSJE2Gz2bBkyRJ07twZW7duxYMPPhj4ytQNWLJkiQKg1q9fr86cOaNOnDihXn/9dVW3bl0VFhamTp48qZRSavDgwQqA+vWvf215/datWxUAtWLFCkv83//+tyVeXFys7Ha76tmzp/J6vb52EyZMUADU4MGDfbGNGzcqAGrjxo1KKaU8Ho9KTU1VycnJ6ty5c5btXL2uUaNGKd3bvx19VEqp5ORklZycLLbnr7KyUlVVVVliBQUFKjQ0VE2ePNkXq94XBQUFlrb+n4dSSvXs2VO77ZkzZyoAavny5b6Y2+1Wbdu2VU6nU5WVlfm2D0DFxcUpl8vlazt+/HgFQN1///3q8uXLvviAAQOU3W5XlZWVSqn//ay6detmeW9z5sxRANTixYt9sczMTAVA/elPf/LFLl26pFq1aqXi4+OV2+229GnJkiW+dhMnTrTs08LCQlWrVi3129/+1vK+9+3bp4KDg0X8RrRo0UI98cQTvuUJEyao2NhYy+eQl5enbDab+ulPfyr26dXHTLNmzVRmZqbYhv/7qabb9xUVFaLdiBEjVHh4uG8/KHXlu+l/LFR/X/2PJR3/7bjdbtW8eXPVuXNnX0y3b6oBUBMnTvQtT58+Xbvt3NxcBUANHz7cEh83bpwCoDZs2OCLJScnKwBq+/btvtgHH3ygAKiwsDB17NgxX3zBggXi+1F9bJ09e9YX27Nnj7LZbOrnP/+5L1a9P/r06WPp01NPPaUAqD179lj6dK085fV6VePGjdWjjz5qORYqKipUamqq6tq1q/jsruWmLq106dIFcXFxuPfee9G/f384nU688847uOeeeyztRo4caVletWoVateuja5du6KkpMT3X0ZGBpxOJzZu3Ajgyi9k9Znf1X9ajh079rp92717NwoKCjB27FhxthXIrWm3q4+FhYXXPRsHrlxbqz5TqKqqwtmzZ+F0OnHfffdh165d1339jVi7di0SEhIwYMAAXywkJARjxoxBeXk5Nm/ebGn/+OOPo3bt2r7lhx56CAAwaNAgBAcHW+JutxtffvklgP/9rMaOHWupZfzyl79EVFQU3nvvPct2goODMWLECN+y3W7HiBEjUFxcjJ07dwb8/t5++214vV5kZ2db9mVCQgIaN27s25c3au/evdi3b5/lcxswYABKSkrwwQcf+GKrV6+G1+vFyy+/LGo4t/o2ybCwMN//f/311ygpKUGHDh1QUVGBQ4cOXfO1S5cuhVIqoNsSr97OuXPncP78eXTo0OG2HJsA8Oyzz1rizz33HACIY6Zp06Zo27atb7n62OzcuTOSkpJE/OjRowCuXFbKzc3FkCFDEBMT42vXsmVLdO3a1dePq40aNcqyPHr0aEufA5Gbm4u8vDwMHDgQZ8+e9R2bFy5cwI9//GNs2bIFXq834PXd1KWVuXPnIj09HcHBwahXrx7uu+8+caAGBwejQYMGllheXh7Onz+P+Ph47XqLi4sBAMeOHQMANG7c2PLvcXFxqFOnzjX7Vn2ZJ5B7kXXuRB+vxev1YtasWZg3bx4KCgos1zivvnR1Kxw7dgyNGzcW++4HP/iB79+vdvUXAoAvqd97773aeHVNoXo99913n6Wd3W5Hw4YNxXYSExMRERFhiaWnpwO48oPYpk2bAN7dlX2plBL7qNrNFqOWL1+OiIgINGzYEPn5+QAAh8OBlJQUrFixwneJ4ciRI7DZbGjatOlNbedGHDhwAL/5zW+wYcMGlJWVWf7t/Pnzt2w7a9aswdSpU5Gbm2u5Vn2rf5iOHTsGm82GRo0aWeIJCQmIjo6+7ccmcOV78MEHH+DChQuW49H/eEpLS4PNZgvoRK1aXl4eAGDw4ME1tjl//nzAueSmEvmDDz6I1q1bX7PN1WeW1bxeL+Lj42u8Vav62tjddLf7+Lvf/Q4vvfQSfvGLX2DKlCmIiYmBzWbD2LFjLb/QNX1xAilu3aya7hCpKa7u8lMEvV4vgoKC8P7772v7WF0ruBFKKaxcuRIXLlzQJuji4mKUl5ff1Lr9BbqPXS4XMjMzERUVhcmTJyMtLQ0OhwO7du3Cr371qxs6s7uWrVu3ok+fPujYsSPmzZuH+vXrIyQkBEuWLLHctXMrj81AfyDu5rF5Mz9i1ftk+vTpaNWqlbbNjRxDt6TYGai0tDSsX78e7du3t/yJ5i85ORnAlV+thg0b+uJnzpwRd47otgEA+/fvR5cuXWpsV9OHfyf6eC1vvvkmHnnkESxatMgSd7lcvmIQAN8vtf9dH/5nKkDN7zU5ORl79+6F1+u1/OhW/yle/R6/qer1HD582PJZud1uFBQUiP1UVFQkzoK++OILALihUYlpaWlQSiE1NdV3Rv9Nbd68GSdPnsTkyZN9f7lUO3fuHJ588kmsXr0agwYNQlpaGrxeLw4ePFjjlxWoef9cvY+vvkzov483bdqEs2fP4u2337aMp6i+i+xWeeutt+BwOPDBBx8gNDTUF1+yZEmN/b7ajR6bXq8XeXl5ls/59OnTcLlct+XY9Hfo0CHExsaKvw7z8vKQmprqW87Pz4fX673hYxMAoqKirpmnAnVHb77Ozs5GVVUVpkyZIv7N4/H4dnyXLl0QEhKC2bNnW345AxnU8qMf/QipqamYOXOmOJCuXlf1zvFvc7v6GOjth7Vq1RJnC6tWrfJdb65WfSBs2bLFF6uqqsLChQvFOiMiIrR/XmdlZeHUqVN44403fDGPx4PZs2fD6XQiMzPzuv0NRJcuXWC32/GXv/zF8t4WLVqE8+fPi7sdPB4PFixY4Ft2u91YsGAB4uLikJGREfB2+/bti1q1aiEnJ0d8pkopnD179obfS/Vlleeffx79+vWz/PfLX/4SjRs39v0199hjj8Fms2Hy5MnirNj/WNTdhqnbxxcuXBC3h1afdV69TrfbjXnz5gX0ngK9/bBWrVoICgqynFkXFhZi9erVlnZRUVGIjY219BuAtj81fQ+zsrIAyO/TK6+8AgA3fIdMTerXr49WrVph2bJllj7s378fH374oa8fV6u+dbna7NmzAVwZXxOojIwMpKWlYcaMGSgvLxf/fubMmYDXBdzhM/LMzEyMGDEC06ZNQ25uLrp164aQkBDk5eVh1apVmDVrFvr164e4uDiMGzcO06ZNQ69evZCVlYXdu3fj/ffft5yV6thsNsyfPx+9e/dGq1atMHToUNSvXx+HDh3CgQMHfMWo6oQwZswYPProo6hVqxb69+9/2/oY6O2HvXr1wuTJkzF06FC0a9cO+/btw4oVKyxnsgDQrFkztGnTBuPHj0dpaSliYmLw+uuvw+PxiHVmZGTgjTfewLPPPosHHngATqcTvXv3xpNPPokFCxZgyJAh2LlzJ1JSUvDmm29i27ZtmDlzJiIjI6/Z10DFxcVh/PjxyMnJQffu3dGnTx8cPnwY8+bNwwMPPIBBgwZZ2icmJuIPf/gDCgsLkZ6ejjfeeAO5ublYuHDhDV3XTktLw9SpUzF+/HgUFhbiscceQ2RkJAoKCvDOO+/gySefxLhx4wBcOat95JFHMHHixBqnbrh06RLeeustdO3aFQ6HQ9umT58+mDVrFoqLi9GoUSO8+OKLmDJlCjp06IC+ffsiNDQUn376KRITEzFt2jQAV/bP/PnzMXXqVDRq1Ajx8fHo3LkzunXrhqSkJAwbNgzPP/88atWqhcWLFyMuLg7Hjx/3bbNdu3aoU6cOBg8ejDFjxiAoKAivvfZawJcPAr39sGfPnnjllVfQvXt3DBw4EMXFxZg7dy4aNWqEvXv3WtoOHz4cv//97zF8+HC0bt0aW7Zs8f1VdbXq7+GLL76I/v37IyQkBL1798b999+PwYMHY+HChb5LR5988gmWLVuGxx57DI888khA7y0Q06dPR48ePdC2bVsMGzbMd/th7dq1tcdCQUEB+vTpg+7du+Ojjz7C8uXLMXDgQNx///0Bb9Nms+Fvf/sbevTogWbNmmHo0KG455578OWXX2Ljxo2IiorCu+++G/ibuJFbXKpve/r000+v2W7w4MEqIiKixn9fuHChysjIUGFhYSoyMlK1aNFCvfDCC6qoqMjXpqqqSuXk5Kj69eursLAw1alTJ7V///7r3tZT7b///a/q2rWrioyMVBEREaply5Zq9uzZvn/3eDxq9OjRKi4uTgUFBYnbvG5lH5W6sdsPn3vuOd8627dvrz766COVmZkpblE7cuSI6tKliwoNDVX16tVTEyZMUOvWrROfR3l5uRo4cKCKjo5WACz9OH36tBo6dKiKjY1VdrtdtWjRQtw2Vn072fTp0y3x6s9+1apVlnhNx8mcOXNUkyZNVEhIiKpXr54aOXKkuEU0MzNTNWvWTH322Weqbdu2yuFwqOTkZDVnzhxtn651+2G1t956Sz388MMqIiJCRUREqCZNmqhRo0apw4cP+9q8++67CoB69dVXxeuvXg8AtWjRohrbbNq0SQFQs2bN8sUWL16sfvjDH6rQ0FBVp04dlZmZqdatW+f791OnTqmePXuqyMhIBcCyn3fu3KkeeughZbfbVVJSknrllVe0tx9u27ZNtWnTRoWFhanExET1wgsv+G7Bu/pY+Ka3Hy5atEg1btxYhYaGqiZNmqglS5ZoP/eKigo1bNgwVbt2bRUZGamys7NVcXGxuP1QKaWmTJmi7rnnHmWz2Sz9uHz5ssrJyVGpqakqJCRE3XvvvWr8+PGW2ymVuvLd6tmzp+grADVq1ChLrKZjef369ap9+/YqLCxMRUVFqd69e6uDBw9a2lS/z4MHD6p+/fqpyMhIVadOHfX000+rixcvij4Fkqd2796t+vbtq+rWratCQ0NVcnKyys7OVv/5z3/E+7mWoP95w0Tfay+88AJWrlyJ/Px8y/VfIhNwghIiABs3bsRLL73EJE5G4hk5EZHheEZORGQ4JnIiIsMxkRMRGY6JnIjIcEzkRESGu6MjO+mbW7N6uYj5z3YHABUotiyXl8sn9qQnyonrK+VoYZSVFYtY/lHrSD6Pt1K0KSqUK3MVukTMHm0XsS/ccpuO2HDL8smiIrkuuzykW7WSk1u1at5KxNo0t04E50C4aFPplk9Qr3TLzz8+NknEvF7rA0fKy+Tnsz13i4gdLyoUsYSEBBFLTJAjiv+b+5lluVQzFYBNftT4cM1+GaRvLZ6RExEZjomciMhwTORERIZjIiciMhyLnYYJj5eFQUeMLHJ5bdGW5QpXhWjjqZRT3sZrimjuClkoLTl5yrJsi5GHUqOmDUXMEyvbebyyHw+ny35ExURZlu12OZVsbIr8LGITokXMqZmG1ubfNZs8z3FXyP6Xlcp94vXKQqbDr79OTUG0eUP5GLtGSY1EzO1xiVh8gnw84dF8a0E4JSpFtGnQNFHEyCw8IyciMhwTORGR4ZjIiYgMx0RORGQ4FjsNkxAjC1/+D/YFAA+sBURbrGxj88rfcWd4jIi5ylwiVl5hfW1phWZIqFsWSctKNcVITaG09JRcX3GRdWRkq5Ypok24V/a/uFAWep0pTrnNUms7T7gcxemQdU24NaNaS4tdIhYfZS1GxsTIfdIkPV3EPO4GInayVI68LKuQI13TU6zHi9MuPx+7pqhLZuEeJCIyHBM5EZHhmMiJiAzHa+SG0c+qJ6+1+vP4zbwHAMGaa6NeyHXFJ6aI2PEi6/XeU5oZGMuK5QXlz3bJa7tt2rUWsZPHT4pYabk11vqg3Kbbs0vEYhNkP7p0lgNvXMXWa+QpreV1ek/wURErL5afYzhkLSAhytpON2ui3S5nXPRoBhe5PfL6fUlJoYg18RtgFG6Xx88pv8FdZB6ekRMRGY6JnIjIcEzkRESGYyInIjIci53fAboCpc3vNzrYJgt+Nu3sfnJwy8H9skC5dec//SJRok0emosYsFdENm+Wg3MAlyZ2yLK0bp0c6APIIqnufOWtlV9o2lkH1DR7QM4m2PkxWYzUjBFCwyhZ7IxKsc7o6Co5LtpUBsvCpi1cbsHlksXOiko5AKvcbX1P/jNIAkBsouwrmYVn5EREhmMiJyIyHBM5EZHhmMiJiAzHYud3gH9hU0c3+tMWLHd/ZYUcARqjKdwB/u1Oa9rIR71BWwDVlQtloVHGZOEOkI+IA2RhEJCFQfgVjQ98elC0OLBLFjtf+n1HEWuQImcZDPZ/1JtNM9NkpRxlWeYqFLHSIjkq9FC+nP3Qf1JKhzNatElPkP0ns/CMnIjIcEzkRESGYyInIjIcEzkRkeFY7PwOCGQaW90ozspyOTIy/6CcptVmkyMvO7R90rK89aPFmq22EpGwuikilt5QFjaLS2Qxz1VhLYrGp8hHoFVoHjnncsl1XT6pKXYq/wKu5nOt+liEPlwri4wd5Sy58Nit63ckyGKn7bhmn+zfLmKV5bJvZcc9IpZfaR3pmpQkR742itWNkCWT8IyciMhwTORERIZjIiciMhwTORGR4VjsNIy+sHn9Yqf/qEIAOJovC1+HDsrpXVMayec8VpT7j6CUozMb/1AWI/t2l1XApIRoEQsPl4fm4tXWvn2SWyzawC774dX07Z7miSJWUmotlNqC5SjOB1t1FrFPPnldxKZOXShiY58cblluEJsi2pSWypGdDdLTRcztdYlYeKL8zD7bZX2G6Wdrc0WbhtFNRaxJepaI0bcXz8iJiAzHRE5EZDgmciIiw/EauXF0v70y5j/+x+uRg0XglTMd6h4FZg+XA4L27su/bh8K810i9seZW0RM8xQ6jBkur6UXnbReE7/0peYaee1oGfNqBkNprqXHx1hjJzSDhsrd8tp6UiPZ1+OagVVH9xdau5UkaxvhMdEi1ihJzhhZVHhIxHbt/0TEygqtg6E8HvmVP5QrZ3ns0k2E6FuMZ+RERIZjIiciMhwTORGR4ZjIiYgMx2KnYbweWaDUDgiyWXet2y1fp3vUW2FRpYitWS9n37ssHp8mB884nLJw+vUpuf6qi3L2vbfXyIFJx0/5z2yoed+aGR3hkIXNcjlJImKcfkVdTX1YN2NktDNFxI7bfyRiHpt1EFV68wdFm6jYaLlR3ftMkgO8UlKOy1iitR9JDVJEm/B4OQsjmYVn5EREhmMiJyIyHBM5EZHhmMiJiAwXpJRSd7sTFLjCvXIUXnCULHzZHdbio+5Rb7s+k+vq22eyiLm9shh2Wfk/3my/aANka2K6+rp8FFtgdXg54lQ3CyMgPx8Eadop/+qm7EOdVDkTZIMGMlZWIWcxbNXQGuvbXTPrYFM5crRheoqIeTQjdW26mrd/QPOx6ibUjI+Xj9+jby+ekRMRGY6JnIjIcEzkRESGYyInIjIcR3Ya5ugne0Usvrl8FFiM38i/YE1Fq7JMFhm7d5JTplZ6okXsvc3+09h+LdoAizSx+zQxWeDTDqsU5x1y5Ki2sKkbGak0QzvhP2ozWrQ4VyCnpz1XkCJiterKAvGxXdbi8qmj/gVjYMJv+opYk6bya+rRjNQVcxdD886v/1RAMhDPyImIDMdETkRkOCZyIiLDMZETERmOxU7DnDwqpyq1RWues+n3IMxSl0u02bVFPuOxQYwsMnrscopaXSEwMLoio458DibgX2DdpWkT4DS/2mKqf4FSN72rHA0LvCkiVWcTRKxWpHU/pbfsJdrExsoRp263nDpXN1KXvr94NBARGY6JnIjIcEzkRESGYyInIjIci52GcVVqRmjuks+3rCy2jtrMPehfKAQOfiyLhYX5spgaHKUbeek/bW0LTZsmmli0JianfNVPR5vlt6wrWB7SxHQjQOVoWP/+1m8s25w6+W8RUxdzNeuSn2PV17GW5dzcj0Wbvy8vFrGUlAYi1jBJfrYPtpEFYmeUdapfr1f3mZHpeEZORGQ4JnIiIsMxkRMRGY7XyE3jkdfInc5oETtVZL3W+tn2LaJNRbkcnFP+tZyRz/u1nCUxzm+5FHIATJX2erhucI7uUW//TxPzv1Z/MsB1yQE1+nafWZa+ytOd58jPBwj0aYnWfuzbLa+H79stawP14ypFzK4ZDDVkuHxPT42VsylKPJ8zHfcgEZHhmMiJiAzHRE5EZDgmciIiw7HYaZjYKPnbmxIrY/9da53Z8K3d6wJafwvUE7Hu/0fO0ucMt86IOPG1VzVrc2linwbUD7193+C13wYX/JYPaNrI2FdnkjXtZHF55u+3i1iXbtZBQk1bysFdHo4RMh7PyImIDMdETkRkOCZyIiLDMZETERmOxU7DFB+XMwUe3SVH+RUVld7U+is0j0pz2uXv/ZaPc8UrJf8ZEgGglibm1MR0j5f7ShP7PtB9TeVozzLlErEvDlpHojZvJWdS9Hp1j8cjk/CMnIjIcEzkRESGYyInIjIcEzkRkeFY7DRMQiPN48ecsSLWIMnvN3rPfwJbf225rg3/lY8k23xiZwBr0z2uTTeNrRxt2KxZdxE7cMBa1A2C7KvCGs36L9XQP39hfssXRYsfpA4WMa+m0Hu4YFWA2/SXJiK1QzqLWFSM/GwbJMii8d5ca8G5e5+Woo3dzjRgOp6RExEZjomciMhwTORERIZjIiciMhyrHIaJaShH5pW65TykhfmFN7X+6Ph4EduQ94mmZSBkX4FDmtjnInLggIz5jwq1BbURLaqUPDfJaDxMxJq2ShGxwuMl1vVrioCJiUkiVumWz8pMSpHrt9msBUq32yVf16CRiH1x9KiIfbRDPoP1xGk5QvPgXus+GDikm2iT3lS3n8gkPCMnIjIcEzkRkeGYyImIDMdr5IbxeuVvb7jDIWPhusE415ebly9iF3H5ptalf5TZN1FlXVLbAnpVVKy8BvzaqvWalpv9luM0bZprYsWamG72Sf99IgcSPfTDJ0Vsx+69mnXt0cSk88o6SKj4VLlo06Q5z+dMxz1IRGQ4JnIiIsMxkRMRGY6JnIjIcCx2GsZTLh/xZQ+Wxc74Bgk3tf4vcfqmXvdttvGjVzRROZgIyPBblgOtgBJNTPeYO93j0/yLnTGixY7d/w5wm4FyWZYqNMePjadzxuMuJCIyHBM5EZHhmMiJiAzHRE5EZDgWOw3jcskRg5UeuRvtweF+kVDN2gJ9BJrpvtbE1t3xXgBnb+G6mmli/vscAKwzJ7rKZOHUxvM543EPEhEZjomciMhwTORERIZjIiciMhyLnYaptMmCltvjFbEKMbDwu1DYtBZs772nn2hx4ssVN732++p3sCwf/upjTSvdlL666W7PiEhG4/9rWf7Rj1JEm7++8YeaO3iVe+LkdLpfnvlC09JaYC0tlaNQKytkGgh3ihB9i/GMnIjIcEzkRESGYyInIjIcEzkRkeFY7DRMWbmcnrayvEzESjUj+G6tIL9ldZu3B/gXbL9JYVPHER7tF0nUtJJfmTqRsvB47utcEbOHW6cb/uL4qcA75+fLM2/c1Ou8iBKx8nJ5PhcTf1Orp7uEZ+RERIZjIiciMhwTORGR4XiN3DCFx8tFzOOVjyQrLtE9auxm+V8PB1LrDbEsF5x+W/O687ewD7ffniPv3tTrzn2t+xrJc6SP9vg/xu3OP1bP5fJ/3Bxw/Lhsl9TwDnSGbhmekRMRGY6JnIjIcEzkRESGYyInIjIci52GOXnKJWJuWeuEVzz+rb1mbdsC3KpmxkW3f9HVrMJmIH42OEfEOnZqLWIezeyBubsOiliw3dpu7vzR36B3N+dUkRw8dvJkpaalQxOjbyuekRMRGY6JnIjIcEzkRESGYyInIjIci52GKS+Xj/OyaQpTCQkNLMsjh74g2ny8fZeI7T68VrPVQ5pYaY19/K4oKS4SsYP75edf5pIFRJdLVqDdlbdytG2gIixLFZWaxwJWaKrlZBSekRMRGY6JnIjIcEzkRESGYyInIjIci52GcZXJaUgbNXKKmCPcWtQ6eTxftCkv1z0OTjeiTxbDwp1+RbNzmpcZ7v33F2hitTUtk0Tk3riWIlZRIYuit5+1wFqpGQZcVn43irB0K/GMnIjIcEzkRESGYyInIjIcEzkRkeFY7DRMQpIsrLm9sgB6ML/YslxSfFK+ziOLnREhcsraC5dlgSzvxCfX7Od3l2663goRKT4jY9GhsbehP9dz2bLkCNdNSaybxpZMwjNyIiLDMZETERmOiZyIyHBM5EREhmOx0zCVlXJ04PFTsrBW6VefLHfLIldlZZRmC3Jd+tGeX+s7+L10REQuoVDETl9qIGK3n3Ua23BnvGhRUur//FUyDc/IiYgMx0RORGQ4JnIiIsPxGrlhThbJ65ll5fK6ts1m3bVer3zElzNaXi+1O+SglQun92t6wmvk11aliR27470IDXvMshweFSPalFfIY4PMwjNyIiLDMZETERmOiZyIyHBM5EREhmOx0zCVmpkOo2Pko97i461FreBg+TivSk2R9NSpIrnR0001PSmouZPfO7U0MV0BUd3mfvxARDp37GhZtkMOKHM45OyWZBaekRMRGY6JnIjIcEzkRESGYyInIjJckFLqdldgiIjoNuIZORGR4ZjIiYgMx0RORGQ4JnIiIsMxkRMRGY6JnIjIcEzkRESGYyInIjIcEzkRkeH+PzVnlkDQvhduAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Load one image\n",
    "image, label = test_dataset[9] #change the values to test with different images/classes from test dataset.\n",
    "input_tensor = image.unsqueeze(0).to(device)  # [1, 3, 32, 32]\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    predicted = torch.argmax(output, dim=1)\n",
    "\n",
    "# Get label names\n",
    "pred_label = class_names[predicted.item()]\n",
    "true_label = class_names[label]\n",
    "\n",
    "# Show image and predictions\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(np.transpose(image.numpy(), (1, 2, 0)))\n",
    "plt.title(f'Predicted: {pred_label}, Actual: {true_label}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0796a0-bd27-466f-966a-525ceb8dec5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
