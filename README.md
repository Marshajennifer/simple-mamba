# simple-mamba
This repository contains a simple PyTorch implementation of the **Mamba** architecture for image classification on the **CIFAR-10** dataset. Mamba is a state space model (SSM) designed to model long-range dependencies efficiently â€” offering an alternative to Transformers in sequence-based vision tasks.
It includes training a model from scratch for image classification tasks.

## ğŸ“Œ Features

- âœ… Trainable Mamba-based classifier for CIFAR-10
- âœ… Clean and minimal PyTorch code
- âœ… Supports training from scratch
- âœ… Easily extendable to other vision tasks or datasets


## ğŸ§  What is Mamba?

[Mamba](https://arxiv.org/abs/2312.00752) is a Selective State Space Model introduced by Gu et al. (2023) for efficient sequence modeling. Unlike Transformers, Mamba avoids attention by using dynamic linear state-space operators with selective memory updates â€” enabling faster and scalable training, even in causal or streaming settings.

---

## ğŸ—‚ï¸ Repository Structure

```bash
ğŸ“¦ Mamba-CIFAR
 â”£ ğŸ“„ mamba_image_classifier.py     # Main training script
 â”£ ğŸ“„ README.md                     # This file
```


## ğŸš€ Getting Started

### 1. Install necessary dependencies:

This project requires Python â‰¥ 3.8 and PyTorch â‰¥ 1.12.

Install all required dependencies using:

```bash
pip install torch torchvision
pip install mamba-ssm causal-conv1d

If you encounter PyTorch version or compiler issues (e.g., during building mamba-ssm), use the following safer option:
```bash
pip install mamba-ssm causal-conv1d --no-build-isolation


### To Clone the Repository

```bash
git clone https://github.com/yourusername/mamba-cifar10.git
cd mamba-cifar10

### Run the .ipynb file to train and test the model.

### Trained model is also uploaded in the repository.
```bash
mamba_cifar.pth
